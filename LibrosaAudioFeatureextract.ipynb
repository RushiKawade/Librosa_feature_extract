{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LibrosaAudioFeatureextract.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RushiKawade/Librosa_feature_extract/blob/master/LibrosaAudioFeatureextract.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxL_C3Ufien9",
        "colab_type": "code",
        "outputId": "14779103-70b0-4435-a62e-7924be5443e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "! git clone https://github.com/RushiKawade/Librosa_feature_extract.git\n",
        "! ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Librosa_feature_extract'...\n",
            "remote: Enumerating objects: 26, done.\u001b[K\n",
            "remote: Counting objects:   3% (1/26)\u001b[K\rremote: Counting objects:   7% (2/26)\u001b[K\rremote: Counting objects:  11% (3/26)\u001b[K\rremote: Counting objects:  15% (4/26)\u001b[K\rremote: Counting objects:  19% (5/26)\u001b[K\rremote: Counting objects:  23% (6/26)\u001b[K\rremote: Counting objects:  26% (7/26)\u001b[K\rremote: Counting objects:  30% (8/26)\u001b[K\rremote: Counting objects:  34% (9/26)\u001b[K\rremote: Counting objects:  38% (10/26)\u001b[K\rremote: Counting objects:  42% (11/26)\u001b[K\rremote: Counting objects:  46% (12/26)\u001b[K\rremote: Counting objects:  50% (13/26)\u001b[K\rremote: Counting objects:  53% (14/26)\u001b[K\rremote: Counting objects:  57% (15/26)\u001b[K\rremote: Counting objects:  61% (16/26)\u001b[K\rremote: Counting objects:  65% (17/26)\u001b[K\rremote: Counting objects:  69% (18/26)\u001b[K\rremote: Counting objects:  73% (19/26)\u001b[K\rremote: Counting objects:  76% (20/26)\u001b[K\rremote: Counting objects:  80% (21/26)\u001b[K\rremote: Counting objects:  84% (22/26)\u001b[K\rremote: Counting objects:  88% (23/26)\u001b[K\rremote: Counting objects:  92% (24/26)\u001b[K\rremote: Counting objects:  96% (25/26)\u001b[K\rremote: Counting objects: 100% (26/26)\u001b[K\rremote: Counting objects: 100% (26/26), done.\u001b[K\n",
            "remote: Compressing objects:   4% (1/22)\u001b[K\rremote: Compressing objects:   9% (2/22)\u001b[K\rremote: Compressing objects:  13% (3/22)\u001b[K\rremote: Compressing objects:  18% (4/22)\u001b[K\rremote: Compressing objects:  22% (5/22)\u001b[K\rremote: Compressing objects:  27% (6/22)\u001b[K\rremote: Compressing objects:  31% (7/22)\u001b[K\rremote: Compressing objects:  36% (8/22)\u001b[K\rremote: Compressing objects:  40% (9/22)\u001b[K\rremote: Compressing objects:  45% (10/22)\u001b[K\rremote: Compressing objects:  50% (11/22)\u001b[K\rremote: Compressing objects:  54% (12/22)\u001b[K\rremote: Compressing objects:  59% (13/22)\u001b[K\rremote: Compressing objects:  63% (14/22)\u001b[K\rremote: Compressing objects:  68% (15/22)\u001b[K\rremote: Compressing objects:  72% (16/22)\u001b[K\rremote: Compressing objects:  77% (17/22)\u001b[K\rremote: Compressing objects:  81% (18/22)\u001b[K\rremote: Compressing objects:  86% (19/22)\u001b[K\rremote: Compressing objects:  90% (20/22)\u001b[K\rremote: Compressing objects:  95% (21/22)\u001b[K\rremote: Compressing objects: 100% (22/22)\u001b[K\rremote: Compressing objects: 100% (22/22), done.\u001b[K\n",
            "Unpacking objects:   3% (1/26)   \rUnpacking objects:   7% (2/26)   \rUnpacking objects:  11% (3/26)   \rUnpacking objects:  15% (4/26)   \rUnpacking objects:  19% (5/26)   \rUnpacking objects:  23% (6/26)   \rUnpacking objects:  26% (7/26)   \rUnpacking objects:  30% (8/26)   \rUnpacking objects:  34% (9/26)   \rUnpacking objects:  38% (10/26)   \rUnpacking objects:  42% (11/26)   \rUnpacking objects:  46% (12/26)   \rUnpacking objects:  50% (13/26)   \rUnpacking objects:  53% (14/26)   \rUnpacking objects:  57% (15/26)   \rremote: Total 26 (delta 5), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects:  61% (16/26)   \rUnpacking objects:  65% (17/26)   \rUnpacking objects:  69% (18/26)   \rUnpacking objects:  73% (19/26)   \rUnpacking objects:  76% (20/26)   \rUnpacking objects:  80% (21/26)   \rUnpacking objects:  84% (22/26)   \rUnpacking objects:  88% (23/26)   \rUnpacking objects:  92% (24/26)   \rUnpacking objects:  96% (25/26)   \rUnpacking objects: 100% (26/26)   \rUnpacking objects: 100% (26/26), done.\n",
            "Librosa_feature_extract  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeoYv0REihiQ",
        "colab_type": "code",
        "outputId": "907f9ce4-87f1-4dd5-9cba-00c4d189bc06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from glob import glob\n",
        "\n",
        "# use local path in case of local run of program.\n",
        "data_dir = './Librosa_feature_extract/voice_data/'\n",
        "audio_files = glob(data_dir  + '*.mp3')\n",
        "\n",
        "\n",
        "print('Number of data files loaded: '+ str(len(audio_files)))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of data files loaded: 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lbSIRT1mRHJ",
        "colab_type": "code",
        "outputId": "144574ac-de1b-4971-cf47-dd3592baceea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "import librosa\n",
        "from librosa import feature\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# y = Time Series Array of audio files. Features will be extracted for each data point separately.\n",
        "# sr is a sampling rate\n",
        "\n",
        "speaker = []\n",
        "res = []\n",
        "\n",
        "for audio_path in audio_files:\n",
        "  # ./pro1/normals/61-70968-0007 (online-audio-converter.com).mp3 is path of file to get name of person slice the file path as shown below. Numbers will be differant in your case.\n",
        "  person = audio_path[37:]\n",
        "  person = person[:-4]\n",
        "  #print(person)\n",
        "  speaker.append(person)\n",
        "\n",
        "\n",
        "  y,sr = librosa.load(audio_path)\n",
        "  features = librosa.feature.mfcc(y,sr)\n",
        "  # You can use these features as it is or take mean for all 20 features for each time point by taking column-wise i.e. convert 20 * n array to 20 * 1by to get 1 feature vector per speaker\n",
        " # print(features.shape) # has a shape of 20 * n\n",
        "  \n",
        "  res.append(np.mean(features,axis=1)) # take row0wise mean\n",
        "\n",
        "\n",
        "df = pd.DataFrame(res)\n",
        "df['speaker']= speaker\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "45\n",
            "./Librosa_feature_extract/voice_data/sham.mp3\n",
            "44\n",
            "./Librosa_feature_extract/voice_data/ram.mp3\n",
            "47\n",
            "./Librosa_feature_extract/voice_data/suresh.mp3\n",
            "47\n",
            "./Librosa_feature_extract/voice_data/ramesh.mp3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPxkTjM4lo5X",
        "colab_type": "code",
        "outputId": "e58abe59-e72e-45aa-a8fc-9694542aed76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "print(df)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            0           1          2  ...        18        19  speaker\n",
            "0 -335.529813  145.489373 -19.930307  ...  6.635087 -3.383496     sham\n",
            "1 -349.737403  135.930302 -25.850653  ...  7.571451 -4.738425      ram\n",
            "2 -349.530621  113.786632  -8.128999  ...  6.840907 -3.350148   suresh\n",
            "3 -345.420417  138.491843 -27.996780  ...  6.598630 -1.566160   ramesh\n",
            "\n",
            "[4 rows x 21 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4X7CloI5Sa-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}